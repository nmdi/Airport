import torch
import cv2
import numpy as np
import os
from ultralytics import YOLOv10
from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor
from PIL import Image

def detection(obj):
    """Nháº­n diá»‡n xe Ä‘áº©y vÃ  bÃ¡nh xe tá»« áº£nh Ä‘áº§u vÃ o, kiá»ƒm tra xem xe cÃ³ náº±m trong vÃ¹ng quy Ä‘á»‹nh khÃ´ng."""
    
    # ğŸ› ï¸ Thiáº¿t láº­p mÃ´ hÃ¬nh YOLO
    model_path = '/content/data/model/train/weights/best.pt'
    model = YOLOv10(model_path)
    
    # ğŸ› ï¸ Thiáº¿t láº­p mÃ´ hÃ¬nh SAM2
    sam2_checkpoint = "/checkpoints/sam2.1_hiera_large.pt"
    model_cfg = "configs/sam2.1/sam2.1_hiera_l.yaml"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)
    predictor = SAM2ImagePredictor(sam2_model)
    
    # ğŸ–¼ï¸ Chuyá»ƒn Ä‘á»•i áº£nh Ä‘áº§u vÃ o
    image_np = np.array(obj.convert("RGB"))
    
    # ğŸ“‚ LÆ°u áº£nh táº¡m Ä‘á»ƒ YOLO xá»­ lÃ½
    temp_image_path = "/content/temp_image.jpg"
    obj.save(temp_image_path)
    
    # ğŸ¯ Dá»± Ä‘oÃ¡n báº±ng YOLO
    results = model.track(source=temp_image_path, save=True, conf=0.5, persist=True)
    
    # ğŸ“Œ Láº¥y danh sÃ¡ch Ä‘á»‘i tÆ°á»£ng
    class_ids = results[0].boxes.cls.int().cpu().tolist()
    boxes = results[0].boxes.xyxy.float().cpu().tolist()

    # ğŸš— Kiá»ƒm tra xem cÃ³ xe Ä‘áº©y khÃ´ng (Giáº£ sá»­ class_id == 2 lÃ  xe Ä‘áº©y)
    has_cart = 2 in class_ids
    cart_boxes = [boxes[i] for i in range(len(class_ids)) if class_ids[i] == 2]

    # ğŸ› Láº¥y vá»‹ trÃ­ bÃ¡nh xe (Giáº£ sá»­ class_id == 1 lÃ  bÃ¡nh xe)
    wheel_boxes = [boxes[i] for i in range(len(class_ids)) if class_ids[i] == 1]
    wheel_points = [(box[0] + box[2]) / 2 for box in wheel_boxes]

    # ğŸ›‘ Náº¿u khÃ´ng cÃ³ xe Ä‘áº©y hoáº·c quÃ¡ Ã­t bÃ¡nh xe, tráº£ vá» OUT
    if not has_cart or len(wheel_boxes) < 2:
        return "OUT", {"cart": has_cart, "wheels": len(wheel_boxes)}

    # ğŸ¯ Dá»± Ä‘oÃ¡n phÃ¢n vÃ¹ng xe Ä‘áº©y báº±ng SAM2
    predictor.set_image(image_np)
    input_point = np.array([[150, 410]])  # ğŸ¯ Äiá»ƒm cá»‘ Ä‘á»‹nh Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vÃ¹ng xe Ä‘áº©y
    input_label = np.array([1])

    masks, scores, _ = predictor.predict(point_coords=input_point, point_labels=input_label, multimask_output=False)
    
    # ğŸ” XÃ¡c Ä‘á»‹nh vÃ¹ng biÃªn xe Ä‘áº©y
    mask_image = masks.astype(np.uint8).reshape(masks.shape[-2:])
    left_most, right_most = mask_image.shape[1] - 1, 0
    for i in range(mask_image.shape[0]):
        for j in range(mask_image.shape[1]):
            if mask_image[i][j] == 1:
                left_most = min(left_most, j)
                right_most = max(right_most, j)
    
    # âœ… Kiá»ƒm tra vá»‹ trÃ­ bÃ¡nh xe
    is_in = all(left_most <= wheel <= right_most for wheel in wheel_points)

    # ğŸ“Œ Káº¿t quáº£ tráº£ vá»
    text = "IN" if is_in else "OUT"
    detected_objects = {"cart": has_cart, "wheels": len(wheel_boxes)}
    
    return text, detected_objects
